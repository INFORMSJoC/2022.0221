solving instance uflp nldep gunluk ../../../../../instances/uflp/gunluk/gunluk-30-60-10.txt sqrt
Set parameter TokenServer to value "licences.gerad.lan"
Set parameter MIPGap to value 1e-06
Set parameter FuncPieceError to value 1e-06
Set parameter Threads to value 1
Set parameter FuncPieces to value -2
Set parameter TimeLimit to value 3600
Gurobi Optimizer version 12.0.2 build v12.0.2rc0 (linux64 - "AlmaLinux 9.6 (Sage Margay)")

CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz, instruction set [SSE2|AVX|AVX2|AVX512]
Thread count: 56 physical cores, 56 logical processors, using up to 1 threads

Non-default parameters:
TimeLimit  3600
MIPGap  1e-06
Threads  1
FuncPieces  -2
FuncPieceError  1e-06

Optimize a model with 1950 rows, 1950 columns and 7350 nonzeros
Model fingerprint: 0xd6831b4f
Model has 30 function constraints treated as nonlinear
  30 POW
Variable types: 1920 continuous, 30 integer (30 binary)
Coefficient statistics:
  Matrix range     [4e-04, 1e+02]
  Objective range  [2e-01, 6e+01]
  Bounds range     [3e-13, 1e+10]
  RHS range        [1e+00, 1e+00]
Warning: Model contains large bounds
         Consider reformulating model or setting NumericFocus parameter
         to avoid numerical issues.

User MIP start did not produce a new incumbent solution

Presolve removed 1860 rows and 90 columns
Presolve time: 0.00s
Presolved: 240 rows, 1861 columns, 3930 nonzeros
Presolved model has 30 nonlinear constraint(s)

Solving non-convex MINLP

Variable types: 1861 continuous, 0 integer (0 binary)
Found heuristic solution: objective 360.7401809

Root relaxation: objective 2.757316e+02, 58 iterations, 0.00 seconds (0.00 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0  275.73165    0   23  360.74018  275.73165  23.6%     -    0s
Another try with MIP start
     0     0  276.00013    0   23  360.74018  276.00013  23.5%     -    0s
     0     2  276.00013    0   23  360.74018  276.00013  23.5%     -    0s
H  139    97                     360.7391800  293.79813  18.6%   2.1    0s
*  504   318              81     360.7390900  294.62258  18.3%   2.3    0s
H  591   347                     359.1404942  296.15698  17.5%   2.4    1s
H  591   347                     359.0318572  296.15698  17.5%   2.4    1s
H  591   327                     357.8055012  296.15698  17.2%   2.4    1s
  NLP heuristic elapsed time = 5.01s
   703   390  355.89554   57    0  357.80550  300.28534  16.1%   2.4    7s
   708   395  326.39572   40    0  357.80550  300.28534  16.1%   2.4   11s
   718   405  347.57042   43    0  357.80550  311.24942  13.0%   2.6   16s
H  720   385                     357.2704342  313.08740  12.4%   2.6   16s
H  720   366                     356.8380404  313.08740  12.3%   2.6   16s
  NLP heuristic elapsed time = 5.01s
   721   367  342.26964   45    0  356.83804  313.08740  12.3%   2.6   24s
  1434   666  338.32059   67   16  356.83804  320.79882  10.1%   2.1   25s
  6284  3389  351.22698   85   12  356.83804  331.66522  7.05%   1.7   30s
 11214  5599  338.54483   70   17  356.83804  335.42160  6.00%   1.7   35s
 15820  7473     cutoff   88       356.83804  337.44281  5.44%   1.8   40s
 20698  9027  353.04063   75   14  356.83804  339.29614  4.92%   1.8   45s
 25769 10748  351.12718   85   16  356.83804  340.53699  4.57%   1.8   50s
 30596 12319  356.69319   79   12  356.83804  341.64150  4.26%   1.9   55s
 35288 13687  348.28120   69   14  356.83804  342.38250  4.05%   1.9   60s
 40103 14920     cutoff   74       356.83804  343.14824  3.84%   1.9   65s
 45059 16274  354.87578   81   15  356.83804  343.76328  3.66%   1.9   70s
 49686 17447  352.55108   72   15  356.83804  344.32829  3.51%   1.9   75s
 54666 18595  351.21731   78   17  356.83804  344.81668  3.37%   1.9   80s
 59569 19554  353.96953   85   14  356.83804  345.35308  3.22%   2.0   85s
 64609 20660  354.35375   90   11  356.83804  345.81767  3.09%   2.0   90s
 69644 21609     cutoff   84       356.83804  346.27977  2.96%   2.0   95s
 74242 22397  355.53045   80   13  356.83804  346.67687  2.85%   2.0  100s
 79272 23097     cutoff   90       356.83804  347.11461  2.72%   2.0  105s
 84306 23873     cutoff   79       356.83804  347.46599  2.63%   2.0  110s
 88980 24505     cutoff   83       356.83804  347.79262  2.53%   2.0  115s
 94013 25160  354.89706   82   13  356.83804  348.11194  2.45%   2.1  120s
 99002 25845  356.29913   78   13  356.83804  348.37473  2.37%   2.1  125s
 103948 26471  353.42710   94   13  356.83804  348.64661  2.30%   2.1  130s
 108914 27065     cutoff   83       356.83804  348.85675  2.24%   2.1  135s
 113845 27782  349.76296   79   16  356.83804  349.06681  2.18%   2.1  140s
 118692 28317     cutoff   78       356.83804  349.26449  2.12%   2.1  145s
 123550 28821  351.57264   87   13  356.83804  349.45613  2.07%   2.1  150s
 128407 29376  354.38032   81   13  356.83804  349.61881  2.02%   2.1  155s
 133165 29848  354.91922   86   13  356.83804  349.77986  1.98%   2.1  160s
 137849 30324     cutoff   81       356.83804  349.91447  1.94%   2.1  165s
 142432 30803  354.79519   86   10  356.83804  350.04531  1.90%   2.1  170s
 147284 31281  355.48576   90   14  356.83804  350.16134  1.87%   2.1  175s
 152125 31648  354.08083   75   17  356.83804  350.28930  1.84%   2.1  180s
 156863 32048  356.71886   87   11  356.83804  350.40976  1.80%   2.1  185s
 161436 32409  356.43190   92   13  356.83804  350.50864  1.77%   2.2  190s
 165841 32746  355.57920   91   12  356.83804  350.61044  1.75%   2.2  195s
 170218 33041  354.98604   90   12  356.83804  350.70865  1.72%   2.2  200s
 174740 33401     cutoff   91       356.83804  350.80474  1.69%   2.2  205s
 179299 33640  354.80737   81   14  356.83804  350.90594  1.66%   2.2  210s
 183771 33856     cutoff  100       356.83804  350.99777  1.64%   2.2  215s
 188329 34118  355.70155   88   15  356.83804  351.09318  1.61%   2.2  220s
 192853 34326     cutoff   88       356.83804  351.17253  1.59%   2.2  225s
 197422 34627  353.49003   74   15  356.83804  351.25182  1.57%   2.2  230s
 201853 34850  353.55032   89   11  356.83804  351.33448  1.54%   2.2  235s
H205382 35083                     356.8380270  351.38996  1.53%   2.2  238s
*205399 35084             115     356.8379995  351.38996  1.53%   2.2  238s
H205577 35090                     356.8379678  351.39418  1.53%   2.2  239s
 206410 35133  353.85942   87   15  356.83797  351.41108  1.52%   2.2  240s
H206439 35134                     356.8379571  351.41175  1.52%   2.2  240s
 210730 35273  356.00340   90   12  356.83796  351.48478  1.50%   2.2  245s
 215420 35419  354.33281   90   12  356.83796  351.56381  1.48%   2.2  250s
 220019 35578     cutoff   84       356.83796  351.63383  1.46%   2.2  255s
 224556 35735  355.13453   93   14  356.83796  351.70267  1.44%   2.2  260s
 229172 35885     cutoff   88       356.83796  351.76570  1.42%   2.3  265s
 233820 36035     cutoff   82       356.83796  351.82980  1.40%   2.3  270s
 238466 36131  353.75237   92   14  356.83796  351.89234  1.39%   2.3  275s
 243105 36246  355.63560   96   12  356.83796  351.95172  1.37%   2.3  280s
 247763 36286  353.88053   85   10  356.83796  352.01321  1.35%   2.3  285s
 252427 36360     cutoff   94       356.83796  352.06921  1.34%   2.3  290s
 257083 36408  353.47335   90   16  356.83796  352.12846  1.32%   2.3  295s
 261726 36481     cutoff   90       356.83796  352.18110  1.31%   2.3  300s
 266443 36476     cutoff   94       356.83796  352.23500  1.29%   2.3  305s
 271138 36537  353.60933   87   11  356.83796  352.28355  1.28%   2.3  310s
 275825 36608  353.60207   91   16  356.83796  352.33745  1.26%   2.3  315s
 280520 36565     cutoff   83       356.83796  352.39094  1.25%   2.3  320s
 285203 36580  353.80960   87   14  356.83796  352.43970  1.23%   2.3  325s
 289968 36545  353.81628   86   12  356.83796  352.49050  1.22%   2.3  330s
 294767 36446  355.49350   91   15  356.83796  352.54163  1.20%   2.3  335s
 299629 36284     cutoff   91       356.83796  352.59608  1.19%   2.3  340s
 304231 36158     cutoff   85       356.83796  352.64256  1.18%   2.4  345s
 309038 35993  355.97032   90   12  356.83796  352.69430  1.16%   2.4  350s
 313811 35766  355.53288   87   14  356.83796  352.74296  1.15%   2.4  355s
 318627 35546     cutoff   88       356.83796  352.79157  1.13%   2.4  360s
 323425 35316     cutoff   82       356.83796  352.83967  1.12%   2.4  365s
 328277 35074     cutoff   88       356.83796  352.88727  1.11%   2.4  370s
 333093 34722  354.51283   85   11  356.83796  352.93669  1.09%   2.4  375s
 337912 34403  354.22953   85   14  356.83796  352.98193  1.08%   2.4  380s
 342709 34098  355.32031   90   12  356.83796  353.02570  1.07%   2.4  385s
 347614 33661     cutoff   94       356.83796  353.07382  1.05%   2.4  390s
 352546 33255  356.24952   88   12  356.83796  353.11901  1.04%   2.4  395s
 357411 32778  353.24406   81   11  356.83796  353.16151  1.03%   2.4  400s
 362226 32375     cutoff   93       356.83796  353.20508  1.02%   2.4  405s
 367032 31929     cutoff   88       356.83796  353.24714  1.01%   2.4  410s
 371830 31473  356.10407   88   15  356.83796  353.29083  0.99%   2.4  415s
 376608 30919  356.82918   94   13  356.83796  353.33804  0.98%   2.4  420s
 381362 30349  354.77671   93   15  356.83796  353.38019  0.97%   2.4  425s
 386069 29758  354.32111   89   13  356.83796  353.42504  0.96%   2.4  430s
 390494 29233     cutoff   87       356.83796  353.46289  0.95%   2.4  435s
 395216 28617  355.47443   85   12  356.83796  353.50608  0.93%   2.4  440s
 399898 27953     cutoff   90       356.83796  353.54928  0.92%   2.4  445s
 404593 27254     cutoff   88       356.83796  353.59503  0.91%   2.4  450s
 409265 26526     cutoff   97       356.83796  353.64017  0.90%   2.4  455s
 413871 25722  354.80437   91   11  356.83796  353.68626  0.88%   2.4  460s
 418485 24926  356.29854  100   13  356.83796  353.73338  0.87%   2.4  465s
 422947 24146     cutoff   85       356.83796  353.77894  0.86%   2.4  470s
 427504 23237  355.30192   90   12  356.83796  353.83053  0.84%   2.4  475s
 432062 22329  354.91239   88   12  356.83796  353.88020  0.83%   2.5  480s
 436564 21393     cutoff   88       356.83796  353.93303  0.81%   2.5  485s
 441028 20409     cutoff   90       356.83796  353.99082  0.80%   2.5  490s
 445450 19429     cutoff   89       356.83796  354.04959  0.78%   2.5  495s
 449828 18387  355.40108   88   13  356.83796  354.11184  0.76%   2.5  500s
 454171 17218     cutoff   88       356.83796  354.17750  0.75%   2.5  505s
 458480 15987     cutoff   91       356.83796  354.24653  0.73%   2.5  510s
 462762 14757     cutoff   90       356.83796  354.32809  0.70%   2.5  515s
 466967 13472     cutoff   95       356.83796  354.40743  0.68%   2.5  520s
 471080 12145  355.57000   89   14  356.83796  354.49881  0.66%   2.5  525s
 475128 10761     cutoff   89       356.83796  354.60063  0.63%   2.5  530s
 479116  9247     cutoff   86       356.83796  354.71977  0.59%   2.5  535s
 483001  7624  355.33269   85   10  356.83796  354.90196  0.54%   2.5  540s
 486762  5843     cutoff   91       356.83796  355.17107  0.47%   2.5  545s
 490494  3517  356.33355   94   13  356.83796  355.75825  0.30%   2.5  550s

Explored 494178 nodes (1258729 simplex iterations) in 554.03 seconds (202.86 work units)
Thread count was 1 (of 56 available processors)

Solution count 7: 356.838 357.27 357.806 ... 360.739

Optimal solution found (tolerance 1.00e-06)
Best objective 3.568379570808e+02, best bound 3.568379067318e+02, gap 0.0000%

User-callback calls 1307909, time in user-callback 0.50 sec
Generating Gunluk and Lee data file ../../../../../instances/uflp/gunluk/gunluk-30-60-10.txt
primal_bound = 356.8379570808038, dual_bound = 356.8379067318124, gap = 1.4109763383915714e-5, time = 554.04
OPTIMAL LOCATIONS:
y[1] = 1.0
y[2] = 1.0
y[3] = 1.0
y[4] = 1.0
y[5] = 1.0
y[6] = 1.0
y[7] = 1.0
y[8] = 1.0
y[9] = 1.0
y[10] = 1.0
y[11] = 1.0
y[12] = 1.0
y[13] = 1.0
y[14] = 1.0
y[15] = 1.0
y[16] = 1.0
y[17] = 1.0
y[18] = 1.0
y[19] = 1.0
y[20] = 1.0
y[21] = 1.0
y[22] = 1.0
y[23] = 1.0
y[24] = 1.0
y[25] = 1.0
y[26] = 1.0
y[27] = 1.0
y[28] = 1.0
y[29] = 1.0
y[30] = 1.0
OPTIMAL WAREHOUSING:
f[1] = 235.0
f[2] = 140.0
f[3] = 6.0
f[7] = 98.0
f[8] = 422.0
f[11] = 79.0
f[15] = 251.0
f[17] = 210.0
f[21] = 299.0
f[22] = 32.0
f[23] = 200.0
f[24] = 434.0
f[25] = 353.0
f[26] = 37.0
f[30] = 29.0
OPTIMAL WAREHOUSING COSTS:
nlobj[1] = 0.2884189854997607
nlobj[2] = 3.5618430150298335
nlobj[3] = 4.37809824910035
nlobj[4] = 0.0
nlobj[5] = 0.0
nlobj[6] = 0.0
nlobj[7] = 4.097571048264474
nlobj[8] = 1.5459909300390928
nlobj[9] = 0.0
nlobj[10] = 0.0
nlobj[11] = 2.5083929911858087
nlobj[12] = 0.0
nlobj[13] = 0.0
nlobj[14] = 0.0
nlobj[15] = 0.2980759551555422
nlobj[16] = 0.0
nlobj[17] = 2.1811744826798716
nlobj[18] = 0.0
nlobj[19] = 0.0
nlobj[20] = 0.0
nlobj[21] = 2.927984697818967
nlobj[22] = 8.088684047983854
nlobj[23] = 5.321518313392966
nlobj[24] = 9.798862133689006
nlobj[25] = 4.59538052003246
nlobj[26] = 1.9455417608889387
nlobj[27] = 0.0
nlobj[28] = 0.0
nlobj[29] = 0.0
nlobj[30] = 4.964612141388385
OPTIMAL ASSIGNMENTS:
x[1, 22] = 1.0
x[1, 34] = 1.0
x[1, 35] = 1.0
x[1, 41] = 1.0
x[1, 53] = 1.0
x[1, 54] = 1.0
x[2, 6] = 1.0
x[2, 20] = 1.0
x[2, 60] = 1.0
x[3, 36] = 1.0
x[7, 28] = 1.0
x[7, 40] = 1.0
x[7, 57] = 1.0
x[8, 1] = 1.0
x[8, 11] = 1.0
x[8, 37] = 1.0
x[8, 38] = 1.0
x[8, 43] = 1.0
x[8, 47] = 1.0
x[8, 49] = 1.0
x[11, 12] = 1.0
x[11, 55] = 1.0
x[15, 29] = 1.0
x[15, 42] = 1.0
x[15, 48] = 1.0
x[15, 59] = 1.0
x[17, 17] = 1.0
x[17, 19] = 1.0
x[17, 21] = 1.0
x[17, 24] = 1.0
x[17, 46] = 1.0
x[17, 58] = 1.0
x[21, 2] = 1.0
x[21, 5] = 1.0
x[21, 14] = 1.0
x[21, 16] = 1.0
x[22, 10] = 1.0
x[23, 9] = 1.0
x[23, 32] = 1.0
x[23, 39] = 1.0
x[23, 44] = 1.0
x[23, 52] = 1.0
x[24, 4] = 1.0
x[24, 8] = 1.0
x[24, 13] = 1.0
x[24, 15] = 1.0
x[24, 18] = 1.0
x[24, 25] = 1.0
x[24, 30] = 1.0
x[24, 50] = 1.0
x[25, 7] = 1.0
x[25, 23] = 1.0
x[25, 27] = 1.0
x[25, 31] = 1.0
x[25, 33] = 1.0
x[25, 45] = 1.0
x[25, 51] = 1.0
x[25, 56] = 1.0
x[26, 3] = 1.0
x[30, 26] = 1.0
fixed costs = 1583.0
assignment costs = 300.33580780865447
warehousing costs = 56.5021492721493
total cost = 356.8379570808038
