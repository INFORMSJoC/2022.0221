solving instance uflp nldep holmberg 39 sqrt
Set parameter TokenServer to value "licences.gerad.lan"
Set parameter MIPGap to value 1e-06
Set parameter FuncPieceError to value 1e-06
Set parameter Threads to value 1
Set parameter FuncPieces to value -2
Set parameter TimeLimit to value 3600
Gurobi Optimizer version 12.0.2 build v12.0.2rc0 (linux64 - "AlmaLinux 9.6 (Sage Margay)")

CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz, instruction set [SSE2|AVX|AVX2|AVX512]
Thread count: 56 physical cores, 56 logical processors, using up to 1 threads

Non-default parameters:
TimeLimit  3600
MIPGap  1e-06
Threads  1
FuncPieces  -2
FuncPieceError  1e-06

Optimize a model with 4740 rows, 4650 columns and 18150 nonzeros
Model fingerprint: 0x4cee3682
Model has 30 function constraints treated as nonlinear
  30 POW
Variable types: 4620 continuous, 30 integer (30 binary)
Coefficient statistics:
  Matrix range     [3e-04, 5e+02]
  Objective range  [1e+00, 3e+03]
  Bounds range     [3e-13, 1e+10]
  RHS range        [1e+00, 1e+00]
Warning: Model contains large bounds
         Consider reformulating model or setting NumericFocus parameter
         to avoid numerical issues.

User MIP start did not produce a new incumbent solution

Presolve removed 4560 rows and 90 columns
Presolve time: 0.01s
Presolved: 330 rows, 4561 columns, 9330 nonzeros
Presolved model has 30 nonlinear constraint(s)

Solving non-convex MINLP

Variable types: 4561 continuous, 0 integer (0 binary)
Found heuristic solution: objective 14253.207228

Root relaxation: objective 8.389000e+03, 94 iterations, 0.00 seconds (0.00 work units)
Another try with MIP start

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0 8389.00000    0   26 14253.2072 8389.00000  41.1%     -    0s
H    0     0                    10158.216438 8389.00000  17.4%     -    0s
     0     0 8390.29626    0   24 10158.2164 8390.29626  17.4%     -    0s
H    0     0                    10007.920568 8390.29626  16.2%     -    0s
H    0     0                    9953.8601796 8390.29626  15.7%     -    0s
     0     2 8390.33507    0   23 9953.86018 8390.33507  15.7%     -    0s
H    3     3                    9876.1235169 8411.17398  14.8%   3.7    0s
H    3     3                    9844.6223361 8411.17398  14.6%   3.7    0s
H    3     3                    9807.2189566 8411.17398  14.2%   3.7    0s
H  300   202                    9619.4261567 8495.57493  11.7%   4.1    1s
H  300   180                    9589.5729679 8495.57493  11.4%   4.1    1s
H  300   170                    9569.0256286 8495.57493  11.2%   4.1    1s
H  300   160                    9538.7644876 8495.57493  10.9%   4.1    1s
  NLP heuristic elapsed time = 5.04s
  NLP heuristic elapsed time = 10.01s
  NLP heuristic elapsed time = 15.01s
   639   348 9393.30324    9    0 9538.76449 8528.30605  10.6%   3.9   18s
  NLP heuristic elapsed time = 5.04s
  NLP heuristic elapsed time = 10.02s
  NLP heuristic elapsed time = 15.01s
   644   353 8626.27932   11    0 9538.76449 8528.30605  10.6%   4.0   35s
  NLP heuristic elapsed time = 5.02s
  NLP heuristic elapsed time = 10.00s
  NLP heuristic elapsed time = 15.03s
   649   358 8790.29338   13    0 9538.76449 8790.29338  7.85%   4.2   52s
  NLP heuristic elapsed time = 5.03s
  NLP heuristic elapsed time = 10.04s
  NLP heuristic elapsed time = 15.03s
   654   363 9085.51778   23    0 9538.76449 8894.88421  6.75%   4.3   69s
H  656   345                    9530.3075549 8925.98054  6.34%   4.3   69s
  NLP heuristic elapsed time = 5.01s
  NLP heuristic elapsed time = 10.01s
  NLP heuristic elapsed time = 15.01s
  NLP heuristic elapsed time = 20.04s
   657   346 9229.03687   40    0 9530.30755 8925.98054  6.34%   4.3   91s
H  657   329                    9530.2533826 8935.81416  6.24%   4.5   91s
H  684   330                    9530.2472095 9021.90030  5.33%   4.5   92s
H  688   317                    9530.2400590 9021.90030  5.33%   4.4   92s
  1688   785 9473.82414   78   16 9530.24006 9061.88633  4.91%   3.7   95s
  3879  1944 9443.46022   68   16 9530.24006 9199.76353  3.47%   3.4  100s
  5993  2902 9521.21331   73    9 9530.24006 9232.96386  3.12%   3.3  105s
  8238  3811 9410.80774   72   17 9530.24006 9256.77327  2.87%   3.3  110s
 10397  4674 9470.12978   70    9 9530.24006 9270.98523  2.72%   3.3  115s
 12615  5490 9527.91225   71    9 9530.24006 9283.19084  2.59%   3.3  120s
 14622  6235 9510.75235   74    9 9530.24006 9293.55367  2.48%   3.3  125s
 16612  6927     cutoff   75      9530.24006 9299.27645  2.42%   3.4  130s
 18818  7649 9451.93230   79   13 9530.24006 9310.51531  2.31%   3.4  135s
 20910  8325     cutoff   76      9530.24006 9315.88899  2.25%   3.4  140s
 23059  8928 9446.39399   76   16 9530.24006 9324.01242  2.16%   3.4  145s
 25136  9573 9506.36154   69   12 9530.24006 9330.07427  2.10%   3.4  150s
 27302 10185 9348.27596   74   12 9530.24006 9334.04128  2.06%   3.5  155s
 29358 10703     cutoff   78      9530.24006 9339.62190  2.00%   3.5  160s
 31526 11235     cutoff   80      9530.24006 9345.22928  1.94%   3.5  165s
 33595 11770 9475.53500   73   11 9530.24006 9348.47850  1.91%   3.5  170s
 35632 12277     cutoff   72      9530.24006 9351.63700  1.87%   3.5  175s
 37610 12717 9492.93440   82   13 9530.24006 9355.20806  1.84%   3.5  180s
 39695 13210 9479.10970   77   18 9530.24006 9358.88882  1.80%   3.5  185s
 41831 13700 9524.62131   80   13 9530.24006 9361.76564  1.77%   3.5  190s
 43841 14166     cutoff   73      9530.24006 9364.15055  1.74%   3.5  195s
 45991 14620     cutoff   67      9530.24006 9367.09643  1.71%   3.6  200s
 48034 15033 9506.90060   67   13 9530.24006 9369.52383  1.69%   3.6  205s
 50224 15441     cutoff   80      9530.24006 9372.66687  1.65%   3.6  210s
 52237 15868     cutoff   71      9530.24006 9374.93394  1.63%   3.6  215s
 54363 16240 9495.22748   79   14 9530.24006 9377.17656  1.61%   3.6  220s
 56527 16628     cutoff   76      9530.24006 9379.43081  1.58%   3.6  225s
 58689 17060     cutoff   77      9530.24006 9381.62307  1.56%   3.6  230s
 60711 17420 9508.19093   74   17 9530.24006 9383.43264  1.54%   3.6  235s
 62735 17712 9509.30966   74   14 9530.24006 9385.88555  1.51%   3.6  240s
 64754 17999 9520.24513   75   18 9530.24006 9387.73359  1.50%   3.6  245s
 66829 18328     cutoff   78      9530.24006 9389.71216  1.47%   3.6  250s
 68813 18642     cutoff   85      9530.24006 9391.12013  1.46%   3.6  255s
 70904 18957 9482.29092   71   16 9530.24006 9392.59358  1.44%   3.6  260s
 72979 19226 9453.20352   70   16 9530.24006 9394.32004  1.43%   3.6  265s
 75075 19568     cutoff   77      9530.24006 9395.87615  1.41%   3.6  270s
 77008 19835     cutoff   78      9530.24006 9397.48866  1.39%   3.6  275s
 78971 20044     cutoff   72      9530.24006 9398.96655  1.38%   3.7  280s
 80940 20277     cutoff   79      9530.24006 9400.51037  1.36%   3.7  285s
 82984 20489     cutoff   78      9530.24006 9401.80680  1.35%   3.7  290s
 84999 20724 9512.38847   75   15 9530.24006 9403.18883  1.33%   3.7  295s
 87007 20942     cutoff   75      9530.24006 9404.56790  1.32%   3.7  300s
 88985 21142 9491.75096   76   13 9530.24006 9405.61813  1.31%   3.7  305s
 90891 21366 9521.74318   80   12 9530.24006 9406.89561  1.29%   3.7  310s
 92894 21563     cutoff   73      9530.24006 9408.00900  1.28%   3.7  315s
 94878 21761     cutoff   76      9530.24006 9409.04473  1.27%   3.7  320s
 96655 21934     cutoff   78      9530.24006 9410.15917  1.26%   3.7  325s
 98639 22138 9470.20242   75   11 9530.24006 9411.24739  1.25%   3.7  330s
 100636 22325 9515.40103   79    8 9530.24006 9412.38310  1.24%   3.7  335s
 102604 22475 9508.51331   79   15 9530.24006 9413.85249  1.22%   3.7  340s
 104396 22595     cutoff   71      9530.24006 9414.83869  1.21%   3.8  345s
 106241 22692 9451.10252   71   16 9530.24006 9415.99562  1.20%   3.8  350s
 108139 22776 9508.78418   74   11 9530.24006 9417.14672  1.19%   3.8  355s
 110065 22886     cutoff   80      9530.24006 9418.26120  1.17%   3.8  360s
 112062 22991     cutoff   79      9530.24006 9419.16439  1.17%   3.8  365s
 113895 23060     cutoff   75      9530.24006 9420.24954  1.15%   3.8  370s
 115750 23159     cutoff   78      9530.24006 9421.21248  1.14%   3.8  375s
 117682 23253     cutoff   73      9530.24006 9422.21247  1.13%   3.8  380s
 119557 23334 9494.04563   76   16 9530.24006 9423.08960  1.12%   3.8  385s
 121515 23442     cutoff   74      9530.24006 9424.02338  1.11%   3.8  390s
 123490 23549 9490.99965   82   10 9530.24006 9424.92716  1.11%   3.8  395s
 125310 23617 9530.09979   72   10 9530.24006 9425.80301  1.10%   3.8  400s
 127169 23706 9501.47165   75   10 9530.24006 9426.74062  1.09%   3.9  405s
 129158 23749 9524.04328   76   11 9530.24006 9427.70091  1.08%   3.9  410s
 131060 23801 9507.92291   81   15 9530.24006 9428.62250  1.07%   3.9  415s
 132979 23874     cutoff   78      9530.24006 9429.53263  1.06%   3.9  420s
 134894 23931 9504.25446   85   13 9530.24006 9430.35701  1.05%   3.9  425s
 136693 23986     cutoff   74      9530.24006 9431.16688  1.04%   3.9  430s
 138627 24032 9512.25106   81   11 9530.24006 9431.94714  1.03%   3.9  435s
 140471 24078     cutoff   71      9530.24006 9432.91017  1.02%   3.9  440s
 142426 24077     cutoff   77      9530.24006 9433.74936  1.01%   3.9  445s
 144261 24062 9519.97524   77   13 9530.24006 9434.70822  1.00%   3.9  450s
 146176 24127 9468.54569   70   16 9530.24006 9435.51388  0.99%   3.9  455s
 148006 24199 9484.80616   71   14 9530.24006 9436.28509  0.99%   4.0  460s
 149952 24213 9458.14218   72   17 9530.24006 9437.25866  0.98%   4.0  465s
 151872 24213 9492.82688   71   15 9530.24006 9437.99350  0.97%   4.0  470s
 153763 24200 9478.62111   75   15 9530.24006 9438.72010  0.96%   4.0  475s
 155742 24191 9484.97258   76   15 9530.24006 9439.51168  0.95%   4.0  480s
 157657 24164     cutoff   79      9530.24006 9440.33238  0.94%   4.0  485s
 159490 24123     cutoff   74      9530.24006 9441.09564  0.94%   4.0  490s
 161437 24130 9512.75761   74   13 9530.24006 9441.87473  0.93%   4.0  495s
 163392 24037 9497.47116   74    9 9530.24006 9442.77925  0.92%   4.0  500s
 165356 24065     cutoff   76      9530.24006 9443.50024  0.91%   4.0  505s
 167267 24006     cutoff   77      9530.24006 9444.43468  0.90%   4.0  510s
 169222 23983     cutoff   80      9530.24006 9445.17037  0.89%   4.0  515s
 171142 23955     cutoff   84      9530.24006 9446.00326  0.88%   4.0  520s
 172989 23934     cutoff   72      9530.24006 9446.85548  0.87%   4.1  525s
 174987 23912     cutoff   80      9530.24006 9447.59345  0.87%   4.1  530s
 177002 23901 9474.58199   68   10 9530.24006 9448.57774  0.86%   4.1  535s
 179025 23850     cutoff   78      9530.24006 9449.48286  0.85%   4.1  540s
 181028 23795 9486.53111   82   14 9530.24006 9450.48936  0.84%   4.1  545s
 183000 23703 9464.62517   74   14 9530.24006 9451.34586  0.83%   4.1  550s
 184825 23654     cutoff   73      9530.24006 9452.08457  0.82%   4.1  555s
 186769 23644 9509.30125   77   15 9530.24006 9452.87785  0.81%   4.1  560s
 188755 23578 9478.46561   77   15 9530.24006 9453.71894  0.80%   4.1  565s
 190698 23529 9525.65080   83    8 9530.24006 9454.58490  0.79%   4.1  570s
 192552 23443 9506.45847   82   11 9530.24006 9455.39249  0.79%   4.1  575s
 194486 23379 9511.96105   79   13 9530.24006 9456.13710  0.78%   4.1  580s
 196409 23302 9509.31146   80   16 9530.24006 9457.07747  0.77%   4.1  585s
 198256 23297 9528.30487   75   11 9530.24006 9457.65798  0.76%   4.1  590s
 200234 23173     cutoff   74      9530.24006 9458.52689  0.75%   4.1  595s
 202182 23147 9505.37057   74   10 9530.24006 9459.30361  0.74%   4.1  600s
 204228 23035     cutoff   76      9530.24006 9460.28352  0.73%   4.2  605s
 206231 22910 9486.59380   79   12 9530.24006 9461.14051  0.73%   4.2  610s
 208166 22747 9528.12147   82   14 9530.24006 9462.03450  0.72%   4.2  615s
 210179 22632 9513.95743   77   12 9530.24006 9462.92928  0.71%   4.2  620s
 212136 22549     cutoff   75      9530.24006 9463.78352  0.70%   4.2  625s
 214204 22403 9506.08253   74   20 9530.24006 9464.71545  0.69%   4.2  630s
 216269 22244 9511.21083   73   11 9530.24006 9465.61417  0.68%   4.2  635s
 218028 22159 9507.76501   81   11 9530.24006 9466.31527  0.67%   4.2  640s
 220097 21964     cutoff   75      9530.24006 9467.13360  0.66%   4.2  645s
 222159 21710 9521.71708   81   10 9530.24006 9468.11188  0.65%   4.2  650s
 224198 21569 9512.90998   77   12 9530.24006 9468.87469  0.64%   4.2  655s
 226159 21386 9493.77124   77   11 9530.24006 9469.67438  0.64%   4.2  660s
 228165 21216     cutoff   87      9530.24006 9470.43968  0.63%   4.2  665s
 230168 21033     cutoff   81      9530.24006 9471.25920  0.62%   4.2  670s
 232221 20832 9479.34012   81   13 9530.24006 9472.02377  0.61%   4.2  675s
 234287 20582 9523.03115   82   11 9530.24006 9472.82847  0.60%   4.2  680s
 236339 20360     cutoff   74      9530.24006 9473.51550  0.60%   4.2  685s
 238374 20223     cutoff   77      9530.24006 9474.26342  0.59%   4.2  690s
 240423 20010 9509.67613   73   15 9530.24006 9475.00005  0.58%   4.2  695s
 242448 19743 9519.74599   77   12 9530.24006 9475.92936  0.57%   4.2  700s
 244494 19437     cutoff   76      9530.24006 9476.78636  0.56%   4.2  705s
 246495 19158     cutoff   80      9530.24006 9477.62144  0.55%   4.2  710s
 248538 18817     cutoff   83      9530.24006 9478.45821  0.54%   4.2  715s
 250492 18489     cutoff   78      9530.24006 9479.30966  0.53%   4.2  720s
 252524 18185 9508.99010   79   11 9530.24006 9480.15915  0.53%   4.2  725s
 254591 17778 9517.83153   79    7 9530.24006 9481.05685  0.52%   4.2  730s
 256653 17376     cutoff   78      9530.24006 9481.90269  0.51%   4.2  735s
 258734 16881 9511.44543   82   15 9530.24006 9483.03994  0.50%   4.2  740s
 260805 16316 9504.17067   74   12 9530.24006 9484.21782  0.48%   4.2  745s
 262828 15721 9523.99594   78   13 9530.24006 9485.32065  0.47%   4.3  750s
 264837 15146 9519.69986   81   12 9530.24006 9486.42448  0.46%   4.3  755s
 266870 14559 9491.30070   77   13 9530.24006 9487.51710  0.45%   4.3  760s
 268829 13936     cutoff   76      9530.24006 9488.51903  0.44%   4.3  765s
 270878 13161     cutoff   75      9530.24006 9489.73430  0.43%   4.3  770s
 272880 12427 9516.59756   75    9 9530.24006 9490.93162  0.41%   4.3  775s
 274919 11612 9513.41492   85   10 9530.24006 9492.04824  0.40%   4.3  780s
 276896 10761     cutoff   77      9530.24006 9493.41696  0.39%   4.3  785s
 278792  9909     cutoff   81      9530.24006 9494.84932  0.37%   4.3  790s
 280488  9123     cutoff   80      9530.24006 9496.32241  0.36%   4.3  795s
 282347  8228     cutoff   76      9530.24006 9498.22032  0.34%   4.3  800s
 284184  7365     cutoff   73      9530.24006 9500.21912  0.32%   4.3  805s
 286006  6611     cutoff   82      9530.24006 9502.47844  0.29%   4.3  810s
 287839  5872 9528.19804   88    8 9530.24006 9504.55362  0.27%   4.3  815s
 289721  4898     cutoff   71      9530.24006 9507.63663  0.24%   4.3  820s
 291454  3943     cutoff   77      9530.24006 9510.94157  0.20%   4.3  825s
 293411  2730 9519.49218   77   12 9530.24006 9515.20750  0.16%   4.4  830s
 295258  1427     cutoff   86      9530.24006 9520.76327  0.10%   4.4  835s
 297163   502 9529.69088   93    7 9530.24006 9526.91652  0.03%   4.4  840s
*298130   199             108    9530.2387908 9529.49201  0.01%   4.4  842s

Explored 298500 nodes (1312341 simplex iterations) in 843.90 seconds (285.48 work units)
Thread count was 1 (of 56 available processors)

Solution count 10: 9530.24 9530.25 9538.76 ... 9953.86

Optimal solution found (tolerance 1.00e-06)
Best objective 9.530238790845e+03, best bound 9.530238790845e+03, gap 0.0000%

User-callback calls 1086686, time in user-callback 0.73 sec
reading holmberg data file ../../../../../instances/uflp/holmberg/p39
primal_bound = 9530.238790845357, dual_bound = 9530.238790845355, gap = 1.9086503953008587e-14, time = 843.91
OPTIMAL LOCATIONS:
y[1] = 1.0
y[2] = 1.0
y[3] = 1.0
y[4] = 1.0
y[5] = 1.0
y[6] = 1.0
y[7] = 1.0
y[8] = 1.0
y[9] = 1.0
y[10] = 1.0
y[11] = 1.0
y[12] = 1.0
y[13] = 1.0
y[14] = 1.0
y[15] = 1.0
y[16] = 1.0
y[17] = 1.0
y[18] = 1.0
y[19] = 1.0
y[20] = 1.0
y[21] = 1.0
y[22] = 1.0
y[23] = 1.0
y[24] = 1.0
y[25] = 1.0
y[26] = 1.0
y[27] = 1.0
y[28] = 1.0
y[29] = 1.0
y[30] = 1.0
OPTIMAL WAREHOUSING:
f[1] = 146.0
f[3] = 187.0
f[6] = 335.0
f[9] = 242.0
f[12] = 433.0
f[15] = 329.0
f[16] = 20.0
f[18] = 399.0
f[21] = 451.0
f[25] = 428.0
OPTIMAL WAREHOUSING COSTS:
nlobj[1] = 110.8574840481079
nlobj[2] = 0.0
nlobj[3] = 125.46205312138179
nlobj[4] = 0.0
nlobj[5] = 0.0
nlobj[6] = 167.92447007574026
nlobj[7] = 0.0
nlobj[8] = 0.0
nlobj[9] = 142.72474081158893
nlobj[10] = 0.0
nlobj[11] = 0.0
nlobj[12] = 190.91290113971365
nlobj[13] = 0.0
nlobj[14] = 0.0
nlobj[15] = 166.41394910221183
nlobj[16] = 41.03044818794584
nlobj[17] = 0.0
nlobj[18] = 183.26439459213486
nlobj[19] = 0.0
nlobj[20] = 0.0
nlobj[21] = 194.84084072501656
nlobj[22] = 0.0
nlobj[23] = 0.0
nlobj[24] = 0.0
nlobj[25] = 189.80750904151392
nlobj[26] = 0.0
nlobj[27] = 0.0
nlobj[28] = 0.0
nlobj[29] = 0.0
nlobj[30] = 0.0
OPTIMAL ASSIGNMENTS:
x[1, 22] = 1.0
x[1, 41] = 1.0
x[1, 61] = 1.0
x[1, 68] = 1.0
x[1, 82] = 1.0
x[1, 126] = 1.0
x[1, 129] = 1.0
x[1, 131] = 1.0
x[1, 141] = 1.0
x[3, 7] = 1.0
x[3, 21] = 1.0
x[3, 27] = 1.0
x[3, 91] = 1.0
x[3, 97] = 1.0
x[3, 105] = 1.0
x[3, 113] = 1.0
x[3, 149] = 1.0
x[6, 6] = 1.0
x[6, 19] = 1.0
x[6, 23] = 1.0
x[6, 25] = 1.0
x[6, 29] = 1.0
x[6, 31] = 1.0
x[6, 51] = 1.0
x[6, 54] = 1.0
x[6, 62] = 1.0
x[6, 90] = 1.0
x[6, 106] = 1.0
x[6, 121] = 1.0
x[6, 127] = 1.0
x[6, 134] = 1.0
x[6, 138] = 1.0
x[6, 148] = 1.0
x[6, 150] = 1.0
x[9, 12] = 1.0
x[9, 13] = 1.0
x[9, 26] = 1.0
x[9, 44] = 1.0
x[9, 50] = 1.0
x[9, 76] = 1.0
x[9, 101] = 1.0
x[9, 110] = 1.0
x[9, 122] = 1.0
x[9, 125] = 1.0
x[9, 135] = 1.0
x[9, 142] = 1.0
x[9, 145] = 1.0
x[12, 2] = 1.0
x[12, 20] = 1.0
x[12, 32] = 1.0
x[12, 34] = 1.0
x[12, 39] = 1.0
x[12, 49] = 1.0
x[12, 58] = 1.0
x[12, 59] = 1.0
x[12, 64] = 1.0
x[12, 65] = 1.0
x[12, 66] = 1.0
x[12, 73] = 1.0
x[12, 94] = 1.0
x[12, 99] = 1.0
x[12, 104] = 1.0
x[12, 108] = 1.0
x[12, 114] = 1.0
x[12, 115] = 1.0
x[12, 116] = 1.0
x[12, 123] = 1.0
x[12, 130] = 1.0
x[12, 132] = 1.0
x[12, 146] = 1.0
x[12, 147] = 1.0
x[15, 4] = 1.0
x[15, 9] = 1.0
x[15, 16] = 1.0
x[15, 17] = 1.0
x[15, 40] = 1.0
x[15, 42] = 1.0
x[15, 46] = 1.0
x[15, 52] = 1.0
x[15, 53] = 1.0
x[15, 60] = 1.0
x[15, 79] = 1.0
x[15, 109] = 1.0
x[15, 111] = 1.0
x[15, 112] = 1.0
x[15, 136] = 1.0
x[15, 144] = 1.0
x[16, 43] = 1.0
x[18, 10] = 1.0
x[18, 15] = 1.0
x[18, 18] = 1.0
x[18, 24] = 1.0
x[18, 47] = 1.0
x[18, 57] = 1.0
x[18, 74] = 1.0
x[18, 84] = 1.0
x[18, 85] = 1.0
x[18, 86] = 1.0
x[18, 87] = 1.0
x[18, 88] = 1.0
x[18, 93] = 1.0
x[18, 95] = 1.0
x[18, 98] = 1.0
x[18, 102] = 1.0
x[18, 103] = 1.0
x[18, 107] = 1.0
x[18, 137] = 1.0
x[18, 140] = 1.0
x[21, 1] = 1.0
x[21, 3] = 1.0
x[21, 5] = 1.0
x[21, 14] = 1.0
x[21, 33] = 1.0
x[21, 35] = 1.0
x[21, 36] = 1.0
x[21, 48] = 1.0
x[21, 55] = 1.0
x[21, 56] = 1.0
x[21, 63] = 1.0
x[21, 71] = 1.0
x[21, 72] = 1.0
x[21, 78] = 1.0
x[21, 81] = 1.0
x[21, 83] = 1.0
x[21, 89] = 1.0
x[21, 100] = 1.0
x[21, 124] = 1.0
x[21, 139] = 1.0
x[21, 143] = 1.0
x[25, 8] = 1.0
x[25, 11] = 1.0
x[25, 28] = 1.0
x[25, 30] = 1.0
x[25, 37] = 1.0
x[25, 38] = 1.0
x[25, 45] = 1.0
x[25, 67] = 1.0
x[25, 69] = 1.0
x[25, 70] = 1.0
x[25, 75] = 1.0
x[25, 77] = 1.0
x[25, 80] = 1.0
x[25, 92] = 1.0
x[25, 96] = 1.0
x[25, 117] = 1.0
x[25, 118] = 1.0
x[25, 119] = 1.0
x[25, 120] = 1.0
x[25, 128] = 1.0
x[25, 133] = 1.0
fixed costs = 15000.0
assignment costs = 8017.0
warehousing costs = 1513.2387908453554
total cost = 9530.238790845355
