solving instance uflp nldep holmberg 35 sqrt
Set parameter TokenServer to value "licences.gerad.lan"
Set parameter MIPGap to value 1e-06
Set parameter FuncPieceError to value 1e-06
Set parameter Threads to value 1
Set parameter FuncPieces to value -2
Set parameter TimeLimit to value 3600
Gurobi Optimizer version 12.0.2 build v12.0.2rc0 (linux64 - "AlmaLinux 9.6 (Sage Margay)")

CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz, instruction set [SSE2|AVX|AVX2|AVX512]
Thread count: 56 physical cores, 56 logical processors, using up to 1 threads

Non-default parameters:
TimeLimit  3600
MIPGap  1e-06
Threads  1
FuncPieces  -2
FuncPieceError  1e-06

Optimize a model with 4740 rows, 4650 columns and 18150 nonzeros
Model fingerprint: 0x4cee3682
Model has 30 function constraints treated as nonlinear
  30 POW
Variable types: 4620 continuous, 30 integer (30 binary)
Coefficient statistics:
  Matrix range     [3e-04, 5e+02]
  Objective range  [1e+00, 3e+03]
  Bounds range     [3e-13, 1e+10]
  RHS range        [1e+00, 1e+00]
Warning: Model contains large bounds
         Consider reformulating model or setting NumericFocus parameter
         to avoid numerical issues.

User MIP start did not produce a new incumbent solution

Presolve removed 4560 rows and 90 columns
Presolve time: 0.01s
Presolved: 330 rows, 4561 columns, 9330 nonzeros
Presolved model has 30 nonlinear constraint(s)

Solving non-convex MINLP

Variable types: 4561 continuous, 0 integer (0 binary)
Found heuristic solution: objective 14253.207228

Root relaxation: objective 8.389000e+03, 94 iterations, 0.00 seconds (0.00 work units)
Another try with MIP start

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0 8389.00000    0   26 14253.2072 8389.00000  41.1%     -    0s
H    0     0                    10158.216438 8389.00000  17.4%     -    0s
     0     0 8390.29626    0   24 10158.2164 8390.29626  17.4%     -    0s
H    0     0                    10007.920568 8390.29626  16.2%     -    0s
H    0     0                    9953.8601796 8390.29626  15.7%     -    0s
     0     2 8390.33507    0   23 9953.86018 8390.33507  15.7%     -    0s
H    3     3                    9876.1235169 8411.17398  14.8%   3.7    0s
H    3     3                    9844.6223361 8411.17398  14.6%   3.7    0s
H    3     3                    9807.2189566 8411.17398  14.2%   3.7    0s
H  300   202                    9619.4261567 8495.57493  11.7%   4.1    1s
H  300   180                    9589.5729679 8495.57493  11.4%   4.1    1s
H  300   170                    9569.0256286 8495.57493  11.2%   4.1    1s
H  300   160                    9538.7644876 8495.57493  10.9%   4.1    1s
  NLP heuristic elapsed time = 5.03s
  NLP heuristic elapsed time = 10.01s
  NLP heuristic elapsed time = 15.04s
   639   348 9393.30324    9    0 9538.76449 8528.30605  10.6%   3.9   20s
  NLP heuristic elapsed time = 5.01s
  NLP heuristic elapsed time = 10.02s
  NLP heuristic elapsed time = 15.01s
   644   353 8626.27932   11    0 9538.76449 8528.30605  10.6%   4.0   38s
  NLP heuristic elapsed time = 5.02s
  NLP heuristic elapsed time = 10.02s
  NLP heuristic elapsed time = 15.03s
   649   358 8790.29338   13    0 9538.76449 8790.29338  7.85%   4.2   56s
  NLP heuristic elapsed time = 5.01s
  NLP heuristic elapsed time = 10.03s
  NLP heuristic elapsed time = 15.00s
   654   363 9085.51778   23    0 9538.76449 8894.88421  6.75%   4.3   74s
H  656   345                    9530.3075549 8925.98054  6.34%   4.3   74s
  NLP heuristic elapsed time = 5.02s
  NLP heuristic elapsed time = 10.02s
  NLP heuristic elapsed time = 15.01s
  NLP heuristic elapsed time = 20.03s
   657   346 9229.03687   40    0 9530.30755 8925.98054  6.34%   4.3   95s
H  657   329                    9530.2533826 8935.81416  6.24%   4.5   95s
H  684   330                    9530.2472095 9021.90030  5.33%   4.5   95s
H  688   317                    9530.2400590 9021.90030  5.33%   4.4   95s
  2123  1072 9482.94718   73   15 9530.24006 9112.65630  4.38%   3.5  100s
  4141  2082 9439.33625   70   16 9530.24006 9203.99545  3.42%   3.4  105s
  6186  3005 9468.20224   76   16 9530.24006 9236.40502  3.08%   3.3  110s
  8238  3811 9410.80774   72   17 9530.24006 9256.77327  2.87%   3.3  115s
 10190  4613 9515.77060   77   15 9530.24006 9269.80384  2.73%   3.3  120s
 12220  5345 9400.91761   70   15 9530.24006 9281.68779  2.61%   3.3  125s
 14042  6047 9508.95751   73   17 9530.24006 9291.21848  2.51%   3.3  130s
 15823  6658 9401.63351   70   12 9530.24006 9297.01675  2.45%   3.4  135s
 17817  7304     cutoff   75      9530.24006 9304.92867  2.36%   3.4  140s
 19734  7937 9458.80763   77   11 9530.24006 9312.94418  2.28%   3.4  145s
 21728  8551 9459.83402   67   13 9530.24006 9318.57859  2.22%   3.4  150s
 23715  9154 9495.77223   73   13 9530.24006 9326.19191  2.14%   3.4  155s
 25621  9706 9464.63690   71   15 9530.24006 9330.96955  2.09%   3.4  160s
 27533 10254 9483.14653   80   13 9530.24006 9334.39360  2.06%   3.5  165s
 29518 10747 9386.04174   70   15 9530.24006 9339.85755  2.00%   3.5  170s
 31526 11235     cutoff   80      9530.24006 9345.22928  1.94%   3.5  175s
 33443 11740     cutoff   74      9530.24006 9348.35874  1.91%   3.5  180s
 35397 12212 9372.25148   72   15 9530.24006 9351.42716  1.88%   3.5  185s
 37302 12647 9487.73302   75   15 9530.24006 9354.73171  1.84%   3.5  190s
 39170 13087 9407.90609   67   10 9530.24006 9358.25683  1.80%   3.5  195s
 41060 13493 9434.08337   74   16 9530.24006 9360.69756  1.78%   3.5  200s
 43035 13994 9514.17489   76   13 9530.24006 9363.29110  1.75%   3.5  205s
 44906 14401 9512.16386   78   17 9530.24006 9365.75614  1.73%   3.6  210s
 46900 14821 9498.34718   74   18 9530.24006 9368.29949  1.70%   3.6  215s
 48786 15165 9382.81877   73   16 9530.24006 9370.70709  1.67%   3.6  220s
 50777 15566 9508.45486   79   14 9530.24006 9373.36506  1.65%   3.6  225s
 52605 15952 9479.48839   82   12 9530.24006 9375.29771  1.63%   3.6  230s
 54551 16268 9429.57903   67   12 9530.24006 9377.29412  1.60%   3.6  235s
 56494 16623 9424.51924   73   16 9530.24006 9379.42983  1.58%   3.6  240s
 58459 17018 9502.77075   77   14 9530.24006 9381.45910  1.56%   3.6  245s
 60291 17334     cutoff   83      9530.24006 9383.06908  1.54%   3.6  250s
 62111 17638 9452.36557   77   11 9530.24006 9385.11329  1.52%   3.6  255s
 63901 17898     cutoff   80      9530.24006 9386.96818  1.50%   3.6  260s
 65813 18168     cutoff   72      9530.24006 9388.89226  1.48%   3.6  265s
 67697 18482 9500.45417   78   14 9530.24006 9390.20491  1.47%   3.6  270s
 69445 18760 9442.61069   73   15 9530.24006 9391.55378  1.46%   3.6  275s
 71306 19011 9472.56877   72   15 9530.24006 9392.90370  1.44%   3.6  280s
 73185 19252 9514.82038   76   12 9530.24006 9394.46176  1.42%   3.6  285s
 75052 19569 9507.64904   79   14 9530.24006 9395.86607  1.41%   3.6  290s
 76786 19807 9495.61208   78   15 9530.24006 9397.30024  1.39%   3.6  295s
 78649 20006 9512.01227   81   11 9530.24006 9398.81757  1.38%   3.6  300s
 80415 20226     cutoff   76      9530.24006 9400.24671  1.36%   3.7  305s
 82155 20400 9471.64225   69   11 9530.24006 9401.34739  1.35%   3.7  310s
 83987 20594 9474.01332   71    7 9530.24006 9402.52678  1.34%   3.7  315s
 85765 20778 9469.65135   72   19 9530.24006 9403.82530  1.33%   3.7  320s
 87583 20984     cutoff   79      9530.24006 9404.90817  1.32%   3.7  325s
 89368 21181 9444.07706   76   14 9530.24006 9405.90054  1.30%   3.7  330s
 91080 21389 9476.36000   72   16 9530.24006 9407.03456  1.29%   3.7  335s
 92883 21562 9501.96290   77   14 9530.24006 9408.00780  1.28%   3.7  340s
 94682 21739 9508.37740   77   16 9530.24006 9408.90952  1.27%   3.7  345s
 96343 21908 9509.09038   79   15 9530.24006 9409.91889  1.26%   3.7  350s
 98150 22085     cutoff   77      9530.24006 9411.00359  1.25%   3.7  355s
 99973 22256 9490.03910   77   14 9530.24006 9412.05654  1.24%   3.7  360s
 101792 22425     cutoff   87      9530.24006 9413.32816  1.23%   3.7  365s
 103496 22531 9528.80646   73    9 9530.24006 9414.33211  1.22%   3.7  370s
 105180 22637 9511.51817   74   13 9530.24006 9415.50963  1.20%   3.8  375s
 106862 22709 9494.23838   78   10 9530.24006 9416.44144  1.19%   3.8  380s
 108541 22802     cutoff   73      9530.24006 9417.33770  1.18%   3.8  385s
 110312 22905     cutoff   77      9530.24006 9418.41944  1.17%   3.8  390s
 112071 22994 9502.58613   78   14 9530.24006 9419.16947  1.17%   3.8  395s
 113812 23063     cutoff   79      9530.24006 9420.21450  1.15%   3.8  400s
 115495 23132 9507.41651   73   15 9530.24006 9421.08148  1.15%   3.8  405s
 117277 23234 9505.71765   77   13 9530.24006 9421.98131  1.14%   3.8  410s
 118950 23291 9488.57258   77   15 9530.24006 9422.79187  1.13%   3.8  415s
 120721 23408 9492.48536   76   17 9530.24006 9423.64214  1.12%   3.8  420s
 122503 23496     cutoff   77      9530.24006 9424.42092  1.11%   3.8  425s
 124174 23579     cutoff   80      9530.24006 9425.27141  1.10%   3.8  430s
 125844 23649     cutoff   73      9530.24006 9426.15083  1.09%   3.9  435s
 127635 23726 9516.86185   75   16 9530.24006 9426.93871  1.08%   3.9  440s
 129440 23749     cutoff   75      9530.24006 9427.80540  1.07%   3.9  445s
 131228 23811 9499.91151   72   14 9530.24006 9428.68417  1.07%   3.9  450s
 132979 23874     cutoff   78      9530.24006 9429.53263  1.06%   3.9  455s
 134701 23918 9468.01518   80   14 9530.24006 9430.23885  1.05%   3.9  460s
 136372 23963     cutoff   71      9530.24006 9431.01236  1.04%   3.9  465s
 138154 24021     cutoff   76      9530.24006 9431.79379  1.03%   3.9  470s
 139786 24061     cutoff   84      9530.24006 9432.54510  1.03%   3.9  475s
 141582 24081 9512.51202   75   14 9530.24006 9433.37436  1.02%   3.9  480s
 143347 24080 9506.51547   72   15 9530.24006 9434.24949  1.01%   3.9  485s
 144997 24070     cutoff   80      9530.24006 9435.05254  1.00%   3.9  490s
 146692 24139     cutoff   73      9530.24006 9435.74834  0.99%   3.9  495s
 148462 24185     cutoff   72      9530.24006 9436.48047  0.98%   4.0  500s
 150226 24207     cutoff   74      9530.24006 9437.35989  0.97%   4.0  505s
 151934 24209     cutoff   74      9530.24006 9438.02625  0.97%   4.0  510s
 153625 24204 9493.64751   77   15 9530.24006 9438.69216  0.96%   4.0  515s
 155408 24199 9498.09807   76   13 9530.24006 9439.37427  0.95%   4.0  520s
 157204 24187 9514.08218   77   15 9530.24006 9440.12414  0.95%   4.0  525s
 158982 24143 9516.33591   78   13 9530.24006 9440.91354  0.94%   4.0  530s
 160665 24130     cutoff   74      9530.24006 9441.56940  0.93%   4.0  535s
 162465 24082     cutoff   78      9530.24006 9442.30805  0.92%   4.0  540s
 164240 24035 9459.78807   78   15 9530.24006 9443.08208  0.91%   4.0  545s
 165990 24031 9472.39012   74   13 9530.24006 9443.83780  0.91%   4.0  550s
 167722 24011     cutoff   77      9530.24006 9444.55985  0.90%   4.0  555s
 169557 23982 9491.99834   76   16 9530.24006 9445.32546  0.89%   4.0  560s
 171352 23957     cutoff   75      9530.24006 9446.05757  0.88%   4.0  565s
 173013 23936 9509.49460   89   11 9530.24006 9446.86743  0.87%   4.1  570s
 174802 23913     cutoff   83      9530.24006 9447.51994  0.87%   4.1  575s
 176594 23909 9492.34202   76   14 9530.24006 9448.37395  0.86%   4.1  580s
 178397 23878 9496.33408   76   16 9530.24006 9449.20711  0.85%   4.1  585s
 180199 23862 9500.11352   72   16 9530.24006 9450.02689  0.84%   4.1  590s
 182022 23751     cutoff   71      9530.24006 9450.83602  0.83%   4.1  595s
 183802 23677 9495.81453   76   16 9530.24006 9451.69169  0.82%   4.1  600s
 185483 23634     cutoff   78      9530.24006 9452.40865  0.82%   4.1  605s
 187225 23644     cutoff   87      9530.24006 9453.05005  0.81%   4.1  610s
 188980 23567     cutoff   77      9530.24006 9453.83222  0.80%   4.1  615s
 190742 23529 9522.57227   78   14 9530.24006 9454.60254  0.79%   4.1  620s
 192485 23450     cutoff   85      9530.24006 9455.35949  0.79%   4.1  625s
 194293 23398 9508.28452   81   14 9530.24006 9456.01521  0.78%   4.1  630s
 196113 23320 9480.76472   81   11 9530.24006 9456.90182  0.77%   4.1  635s
 197791 23294 9518.68290   81   10 9530.24006 9457.50848  0.76%   4.1  640s
 199567 23234 9486.57129   72   14 9530.24006 9458.21893  0.76%   4.1  645s
 201352 23179 9514.48704   78   13 9530.24006 9458.97243  0.75%   4.1  650s
 203175 23098 9485.76619   74   13 9530.24006 9459.75691  0.74%   4.2  655s
 205057 22970 9517.42942   78    9 9530.24006 9460.65587  0.73%   4.2  660s
 206930 22837 9493.77380   75   13 9530.24006 9461.50351  0.72%   4.2  665s
 208666 22719     cutoff   79      9530.24006 9462.19142  0.71%   4.2  670s
 210464 22627 9502.16368   82   13 9530.24006 9463.01002  0.71%   4.2  675s
 212208 22551 9511.87454   79    9 9530.24006 9463.81985  0.70%   4.2  680s
 213999 22424     cutoff   80      9530.24006 9464.61897  0.69%   4.2  685s
 215789 22264     cutoff   78      9530.24006 9465.43063  0.68%   4.2  690s
 217300 22231 9521.56333   80   11 9530.24006 9465.97908  0.67%   4.2  695s
 219182 22075     cutoff   84      9530.24006 9466.73958  0.67%   4.2  700s
 221067 21838 9510.47175   71   15 9530.24006 9467.60763  0.66%   4.2  705s
 222952 21655 9519.34335   79   11 9530.24006 9468.41215  0.65%   4.2  710s
 224789 21514 9493.96146   78   13 9530.24006 9469.08403  0.64%   4.2  715s
 226608 21351     cutoff   80      9530.24006 9469.83458  0.63%   4.2  720s
 228440 21185     cutoff   75      9530.24006 9470.54716  0.63%   4.2  725s
 230325 21012     cutoff   71      9530.24006 9471.31452  0.62%   4.2  730s
 232221 20832 9479.34012   81   13 9530.24006 9472.02377  0.61%   4.2  735s
 234113 20594     cutoff   78      9530.24006 9472.76307  0.60%   4.2  740s
 236000 20389 9501.98683   73    4 9530.24006 9473.42581  0.60%   4.2  745s
 237834 20241 9493.13559   80   10 9530.24006 9474.07143  0.59%   4.2  750s
 239720 20055     cutoff   81      9530.24006 9474.83823  0.58%   4.2  755s
 241550 19857 9498.34676   79   13 9530.24006 9475.55488  0.57%   4.2  760s
 243380 19613     cutoff   74      9530.24006 9476.32467  0.57%   4.2  765s
 245256 19339 9523.99624   77   10 9530.24006 9477.09512  0.56%   4.2  770s
 247131 19042     cutoff   77      9530.24006 9477.89495  0.55%   4.2  775s
 248910 18755 9501.55356   74   12 9530.24006 9478.61037  0.54%   4.2  780s
 250771 18468     cutoff   77      9530.24006 9479.40004  0.53%   4.2  785s
 252625 18174 9509.00380   78   13 9530.24006 9480.18668  0.53%   4.2  790s
 254515 17786     cutoff   70      9530.24006 9481.02772  0.52%   4.2  795s
 256343 17452     cutoff   74      9530.24006 9481.74906  0.51%   4.2  800s
 258214 17023 9520.34758   75    8 9530.24006 9482.76488  0.50%   4.2  805s
 260145 16506 9490.52810   73   13 9530.24006 9483.84260  0.49%   4.2  810s
 262082 15953     cutoff   83      9530.24006 9484.90612  0.48%   4.3  815s
 263959 15384 9506.86942   74   15 9530.24006 9485.95871  0.46%   4.3  820s
 265807 14866     cutoff   79      9530.24006 9486.92310  0.45%   4.3  825s
 267483 14396 9518.87547   85   10 9530.24006 9487.82499  0.45%   4.3  830s
 269360 13743 9513.70521   78   15 9530.24006 9488.84236  0.43%   4.3  835s
 271183 13058 9501.78739   77   12 9530.24006 9489.92948  0.42%   4.3  840s
 272959 12396 9519.00464   77   14 9530.24006 9490.97420  0.41%   4.3  845s
 274753 11674     cutoff   82      9530.24006 9491.96278  0.40%   4.3  850s
 276531 10928 9504.99918   79   14 9530.24006 9493.13993  0.39%   4.3  855s
 278280 10109 9525.00890   88    9 9530.24006 9494.48239  0.38%   4.3  860s
 279875  9420     cutoff   91      9530.24006 9495.81997  0.36%   4.3  865s
 281563  8604     cutoff   82      9530.24006 9497.44158  0.34%   4.3  870s
 283266  7783     cutoff   77      9530.24006 9499.18297  0.33%   4.3  875s
 284961  7058     cutoff   75      9530.24006 9501.09402  0.31%   4.3  880s
 286622  6363 9517.82719   76   12 9530.24006 9503.18304  0.28%   4.3  885s
 288263  5660 9530.06994   72   10 9530.24006 9505.22175  0.26%   4.3  890s
 289923  4790     cutoff   78      9530.24006 9507.93864  0.23%   4.3  895s
 291481  3926     cutoff   78      9530.24006 9510.98657  0.20%   4.3  900s
 293182  2885     cutoff   84      9530.24006 9514.58388  0.16%   4.4  905s
 294791  1754     cutoff   88      9530.24006 9519.09472  0.12%   4.4  910s
 296532   765     cutoff   91      9530.24006 9524.75333  0.06%   4.4  915s
*298130   199             108    9530.2387908 9529.49201  0.01%   4.4  919s
 298150   187     cutoff   87      9530.23879 9529.51691  0.01%   4.4  920s

Explored 298500 nodes (1312341 simplex iterations) in 920.94 seconds (285.48 work units)
Thread count was 1 (of 56 available processors)

Solution count 10: 9530.24 9530.25 9538.76 ... 9953.86

Optimal solution found (tolerance 1.00e-06)
Best objective 9.530238790845e+03, best bound 9.530238790845e+03, gap 0.0000%

User-callback calls 1087524, time in user-callback 0.81 sec
reading holmberg data file ../../../../../instances/uflp/holmberg/p35
primal_bound = 9530.238790845357, dual_bound = 9530.238790845355, gap = 1.9086503953008587e-14, time = 920.95
OPTIMAL LOCATIONS:
y[1] = 1.0
y[2] = 1.0
y[3] = 1.0
y[4] = 1.0
y[5] = 1.0
y[6] = 1.0
y[7] = 1.0
y[8] = 1.0
y[9] = 1.0
y[10] = 1.0
y[11] = 1.0
y[12] = 1.0
y[13] = 1.0
y[14] = 1.0
y[15] = 1.0
y[16] = 1.0
y[17] = 1.0
y[18] = 1.0
y[19] = 1.0
y[20] = 1.0
y[21] = 1.0
y[22] = 1.0
y[23] = 1.0
y[24] = 1.0
y[25] = 1.0
y[26] = 1.0
y[27] = 1.0
y[28] = 1.0
y[29] = 1.0
y[30] = 1.0
OPTIMAL WAREHOUSING:
f[1] = 146.0
f[3] = 187.0
f[6] = 335.0
f[9] = 242.0
f[12] = 433.0
f[15] = 329.0
f[16] = 20.0
f[18] = 399.0
f[21] = 451.0
f[25] = 428.0
OPTIMAL WAREHOUSING COSTS:
nlobj[1] = 110.8574840481079
nlobj[2] = 0.0
nlobj[3] = 125.46205312138179
nlobj[4] = 0.0
nlobj[5] = 0.0
nlobj[6] = 167.92447007574026
nlobj[7] = 0.0
nlobj[8] = 0.0
nlobj[9] = 142.72474081158893
nlobj[10] = 0.0
nlobj[11] = 0.0
nlobj[12] = 190.91290113971365
nlobj[13] = 0.0
nlobj[14] = 0.0
nlobj[15] = 166.41394910221183
nlobj[16] = 41.03044818794584
nlobj[17] = 0.0
nlobj[18] = 183.26439459213486
nlobj[19] = 0.0
nlobj[20] = 0.0
nlobj[21] = 194.84084072501656
nlobj[22] = 0.0
nlobj[23] = 0.0
nlobj[24] = 0.0
nlobj[25] = 189.80750904151392
nlobj[26] = 0.0
nlobj[27] = 0.0
nlobj[28] = 0.0
nlobj[29] = 0.0
nlobj[30] = 0.0
OPTIMAL ASSIGNMENTS:
x[1, 22] = 1.0
x[1, 41] = 1.0
x[1, 61] = 1.0
x[1, 68] = 1.0
x[1, 82] = 1.0
x[1, 126] = 1.0
x[1, 129] = 1.0
x[1, 131] = 1.0
x[1, 141] = 1.0
x[3, 7] = 1.0
x[3, 21] = 1.0
x[3, 27] = 1.0
x[3, 91] = 1.0
x[3, 97] = 1.0
x[3, 105] = 1.0
x[3, 113] = 1.0
x[3, 149] = 1.0
x[6, 6] = 1.0
x[6, 19] = 1.0
x[6, 23] = 1.0
x[6, 25] = 1.0
x[6, 29] = 1.0
x[6, 31] = 1.0
x[6, 51] = 1.0
x[6, 54] = 1.0
x[6, 62] = 1.0
x[6, 90] = 1.0
x[6, 106] = 1.0
x[6, 121] = 1.0
x[6, 127] = 1.0
x[6, 134] = 1.0
x[6, 138] = 1.0
x[6, 148] = 1.0
x[6, 150] = 1.0
x[9, 12] = 1.0
x[9, 13] = 1.0
x[9, 26] = 1.0
x[9, 44] = 1.0
x[9, 50] = 1.0
x[9, 76] = 1.0
x[9, 101] = 1.0
x[9, 110] = 1.0
x[9, 122] = 1.0
x[9, 125] = 1.0
x[9, 135] = 1.0
x[9, 142] = 1.0
x[9, 145] = 1.0
x[12, 2] = 1.0
x[12, 20] = 1.0
x[12, 32] = 1.0
x[12, 34] = 1.0
x[12, 39] = 1.0
x[12, 49] = 1.0
x[12, 58] = 1.0
x[12, 59] = 1.0
x[12, 64] = 1.0
x[12, 65] = 1.0
x[12, 66] = 1.0
x[12, 73] = 1.0
x[12, 94] = 1.0
x[12, 99] = 1.0
x[12, 104] = 1.0
x[12, 108] = 1.0
x[12, 114] = 1.0
x[12, 115] = 1.0
x[12, 116] = 1.0
x[12, 123] = 1.0
x[12, 130] = 1.0
x[12, 132] = 1.0
x[12, 146] = 1.0
x[12, 147] = 1.0
x[15, 4] = 1.0
x[15, 9] = 1.0
x[15, 16] = 1.0
x[15, 17] = 1.0
x[15, 40] = 1.0
x[15, 42] = 1.0
x[15, 46] = 1.0
x[15, 52] = 1.0
x[15, 53] = 1.0
x[15, 60] = 1.0
x[15, 79] = 1.0
x[15, 109] = 1.0
x[15, 111] = 1.0
x[15, 112] = 1.0
x[15, 136] = 1.0
x[15, 144] = 1.0
x[16, 43] = 1.0
x[18, 10] = 1.0
x[18, 15] = 1.0
x[18, 18] = 1.0
x[18, 24] = 1.0
x[18, 47] = 1.0
x[18, 57] = 1.0
x[18, 74] = 1.0
x[18, 84] = 1.0
x[18, 85] = 1.0
x[18, 86] = 1.0
x[18, 87] = 1.0
x[18, 88] = 1.0
x[18, 93] = 1.0
x[18, 95] = 1.0
x[18, 98] = 1.0
x[18, 102] = 1.0
x[18, 103] = 1.0
x[18, 107] = 1.0
x[18, 137] = 1.0
x[18, 140] = 1.0
x[21, 1] = 1.0
x[21, 3] = 1.0
x[21, 5] = 1.0
x[21, 14] = 1.0
x[21, 33] = 1.0
x[21, 35] = 1.0
x[21, 36] = 1.0
x[21, 48] = 1.0
x[21, 55] = 1.0
x[21, 56] = 1.0
x[21, 63] = 1.0
x[21, 71] = 1.0
x[21, 72] = 1.0
x[21, 78] = 1.0
x[21, 81] = 1.0
x[21, 83] = 1.0
x[21, 89] = 1.0
x[21, 100] = 1.0
x[21, 124] = 1.0
x[21, 139] = 1.0
x[21, 143] = 1.0
x[25, 8] = 1.0
x[25, 11] = 1.0
x[25, 28] = 1.0
x[25, 30] = 1.0
x[25, 37] = 1.0
x[25, 38] = 1.0
x[25, 45] = 1.0
x[25, 67] = 1.0
x[25, 69] = 1.0
x[25, 70] = 1.0
x[25, 75] = 1.0
x[25, 77] = 1.0
x[25, 80] = 1.0
x[25, 92] = 1.0
x[25, 96] = 1.0
x[25, 117] = 1.0
x[25, 118] = 1.0
x[25, 119] = 1.0
x[25, 120] = 1.0
x[25, 128] = 1.0
x[25, 133] = 1.0
fixed costs = 15000.0
assignment costs = 8017.0
warehousing costs = 1513.2387908453554
total cost = 9530.238790845355
