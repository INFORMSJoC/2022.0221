solving instance uflp nldep holmberg 32 sqrt
Set parameter TokenServer to value "licences.gerad.lan"
Set parameter MIPGap to value 1e-06
Set parameter FuncPieceError to value 1e-06
Set parameter Threads to value 1
Set parameter FuncPieces to value -2
Set parameter TimeLimit to value 3600
Gurobi Optimizer version 12.0.2 build v12.0.2rc0 (linux64 - "AlmaLinux 9.6 (Sage Margay)")

CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz, instruction set [SSE2|AVX|AVX2|AVX512]
Thread count: 56 physical cores, 56 logical processors, using up to 1 threads

Non-default parameters:
TimeLimit  3600
MIPGap  1e-06
Threads  1
FuncPieces  -2
FuncPieceError  1e-06

Optimize a model with 4740 rows, 4650 columns and 18150 nonzeros
Model fingerprint: 0x62d4daee
Model has 30 function constraints treated as nonlinear
  30 POW
Variable types: 4620 continuous, 30 integer (30 binary)
Coefficient statistics:
  Matrix range     [3e-04, 7e+02]
  Objective range  [1e+00, 3e+03]
  Bounds range     [3e-13, 1e+10]
  RHS range        [1e+00, 1e+00]
Warning: Model contains large bounds
         Consider reformulating model or setting NumericFocus parameter
         to avoid numerical issues.

User MIP start did not produce a new incumbent solution

Presolve removed 4560 rows and 90 columns
Presolve time: 0.01s
Presolved: 330 rows, 4561 columns, 9330 nonzeros
Presolved model has 30 nonlinear constraint(s)

Solving non-convex MINLP

Variable types: 4561 continuous, 0 integer (0 binary)
Found heuristic solution: objective 15029.007590

Root relaxation: objective 8.589000e+03, 102 iterations, 0.00 seconds (0.00 work units)
Another try with MIP start

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0 8589.00000    0   26 15029.0076 8589.00000  42.9%     -    0s
H    0     0                    11024.301729 8589.00000  22.1%     -    0s
     0     0 8590.68784    0   26 11024.3017 8590.68784  22.1%     -    0s
H    0     0                    10975.513622 8590.68784  21.7%     -    0s
H    0     0                    10823.509857 8590.68784  20.6%     -    0s
     0     2 8590.70043    0   25 10823.5099 8590.70043  20.6%     -    0s
H    3     3                    10669.544854 8614.48263  19.3%   3.0    0s
H    3     3                    10657.694572 8614.48263  19.2%   3.0    0s
H    3     3                    10544.703888 8614.48263  18.3%   3.0    0s
H  300   192                    10208.550562 8759.65124  14.2%   3.9    1s
H  300   192                    10204.208208 8759.65124  14.2%   3.9    1s
H  300   178                    10167.329743 8759.65124  13.8%   3.9    1s
H  300   178                    10167.007464 8759.65124  13.8%   3.9    1s
H  300   166                    10127.432271 8759.65124  13.5%   3.9    1s
H  300   166                    10127.429540 8759.65124  13.5%   3.9    1s
  NLP heuristic elapsed time = 5.02s
  NLP heuristic elapsed time = 10.03s
   625   356 9748.08990   26    0 10127.4295 8815.86940  13.0%   4.1   15s
  NLP heuristic elapsed time = 5.00s
  NLP heuristic elapsed time = 10.01s
   630   361 9858.76250   32    0 10127.4295 8815.86940  13.0%   4.2   29s
  NLP heuristic elapsed time = 5.02s
  NLP heuristic elapsed time = 10.02s
   635   366 10077.3949   38    0 10127.4295 9076.87068  10.4%   4.4   44s
  NLP heuristic elapsed time = 5.01s
  NLP heuristic elapsed time = 10.03s
  NLP heuristic elapsed time = 15.04s
   640   371 10065.1067   50    0 10127.4295 9170.81485  9.45%   4.6   59s
H  642   353                    10127.246557 9207.61630  9.08%   4.6   59s
H  642   335                    10127.201886 9207.61630  9.08%   4.6   59s
H  642   318                    10126.865938 9207.61630  9.08%   4.6   59s
  NLP heuristic elapsed time = 5.03s
  NLP heuristic elapsed time = 10.02s
  NLP heuristic elapsed time = 15.04s
   643   319 9341.43500   27    0 10126.8659 9207.61630  9.08%   4.6   79s
H  688   333                    10126.072434 9353.52924  7.63%   4.7   79s
H  785   352                    10126.039356 9362.98174  7.54%   4.7   79s
H  785   338                    10126.030607 9362.98174  7.54%   4.7   79s
   785   340 10032.2025   72   16 10126.0306 9362.98174  7.54%   4.7   80s
H  826   340                    10121.430607 9362.98174  7.49%   4.7   80s
  3124  1571 9748.00724   64   16 10121.4306 9582.63791  5.32%   3.7   85s
H 3941  1926                    10119.698782 9630.65345  4.83%   3.7   86s
H 3941  1926                    10119.080633 9630.65345  4.83%   3.7   86s
H 3941  1926                    10118.713061 9630.65345  4.82%   3.7   86s
  5441  2562 10047.1598   69   13 10118.7131 9671.79955  4.42%   3.7   90s
H 6890  3093                    10118.096941 9707.77491  4.06%   3.8   93s
  7695  3364     cutoff   77      10118.0969 9721.68263  3.92%   3.8   95s
H 7890  3411                    10117.911789 9722.60391  3.91%   3.8   95s
  9799  4058 10081.6687   73   17 10117.9118 9745.55700  3.68%   3.9  100s
 11946  4679     cutoff   70      10117.9118 9769.38241  3.44%   4.0  105s
 14249  5286 10041.7666   75   15 10117.9118 9786.39691  3.28%   4.0  110s
 16285  5836 9912.61327   69   15 10117.9118 9800.43306  3.14%   4.1  115s
 18588  6413 9965.51360   70   16 10117.9118 9814.47882  3.00%   4.1  120s
 20796  6969 10068.1394   71   15 10117.9118 9824.99103  2.90%   4.1  125s
 22919  7498 9964.03348   74   18 10117.9118 9834.78782  2.80%   4.1  130s
 25048  7979 9994.41354   70   15 10117.9118 9842.55770  2.72%   4.2  135s
 27349  8512     cutoff   74      10117.9118 9852.62431  2.62%   4.2  140s
 29506  8957     cutoff   83      10117.9118 9859.89156  2.55%   4.2  145s
 31791  9442 10067.2812   76   16 10117.9118 9867.27328  2.48%   4.2  150s
 33971  9902 10099.1295   69   11 10117.9118 9873.89841  2.41%   4.2  155s
 36320 10331 10067.4154   76   17 10117.9118 9880.00368  2.35%   4.2  160s
 38603 10676 10116.8951   71   13 10117.9118 9886.37531  2.29%   4.3  165s
 40820 10977 10012.6229   69   14 10117.9118 9891.42697  2.24%   4.3  170s
 43117 11336 9936.10206   67   11 10117.9118 9896.95589  2.18%   4.3  175s
 45259 11664 10048.6244   70   10 10117.9118 9902.28887  2.13%   4.3  180s
 47416 11985     cutoff   72      10117.9118 9907.67195  2.08%   4.3  185s
 49592 12223 9985.42282   67   13 10117.9118 9912.97815  2.03%   4.3  190s
 51856 12537     cutoff   72      10117.9118 9916.75396  1.99%   4.3  195s
 54080 12777     cutoff   71      10117.9118 9921.18007  1.94%   4.3  200s
 56361 13038     cutoff   72      10117.9118 9925.13546  1.91%   4.3  205s
 58450 13277 10091.2706   74   13 10117.9118 9928.90379  1.87%   4.3  210s
 60604 13553 10091.1858   74   11 10117.9118 9932.05163  1.84%   4.3  215s
 62855 13768 10112.6233   69    5 10117.9118 9935.65865  1.80%   4.4  220s
 65001 13962 10108.7315   76   15 10117.9118 9938.50124  1.77%   4.4  225s
 67130 14157 10051.6817   71   15 10117.9118 9941.93870  1.74%   4.4  230s
 69397 14284     cutoff   79      10117.9118 9945.50260  1.70%   4.4  235s
 71622 14437 10049.4551   78   12 10117.9118 9949.62235  1.66%   4.4  240s
 73746 14539 10106.3890   75   10 10117.9118 9952.88812  1.63%   4.4  245s
 75983 14632 10081.7558   69   13 10117.9118 9956.15813  1.60%   4.4  250s
 78236 14721 10037.5924   73   15 10117.9118 9959.17343  1.57%   4.4  255s
 80356 14811 10087.5808   76   14 10117.9118 9962.38026  1.54%   4.4  260s
 82581 14854 10089.7948   79   16 10117.9118 9965.28538  1.51%   4.4  265s
 84605 14930 10079.7031   69   12 10117.9118 9967.93678  1.48%   4.5  270s
 86821 14952 10072.6911   74   14 10117.9118 9970.74167  1.45%   4.5  275s
 89068 14937     cutoff   73      10117.9118 9973.32662  1.43%   4.5  280s
 91133 14982 10093.0399   74   13 10117.9118 9975.87245  1.40%   4.5  285s
 93255 14952 10067.4614   77   17 10117.9118 9978.41316  1.38%   4.5  290s
 95480 14925 10108.1254   74    6 10117.9118 9980.87183  1.35%   4.5  295s
 97702 14899 10056.3774   77   17 10117.9118 9983.41029  1.33%   4.5  300s
 99893 14882     cutoff   80      10117.9118 9985.91866  1.30%   4.5  305s
 102115 14840 10053.7050   70   11 10117.9118 9988.43925  1.28%   4.5  310s
 104221 14778 10056.9543   71   14 10117.9118 9990.94002  1.25%   4.5  315s
 106404 14695     cutoff   75      10117.9118 9993.19741  1.23%   4.5  320s
 108619 14578 10068.7745   73   14 10117.9118 9995.61751  1.21%   4.5  325s
 110721 14482 10056.3614   74   15 10117.9118 9997.65008  1.19%   4.5  330s
 112918 14317 10071.0010   73   18 10117.9118 10000.1614  1.16%   4.6  335s
 115105 14186 10112.4954   71    9 10117.9118 10002.6986  1.14%   4.6  340s
 117273 14022     cutoff   77      10117.9118 10005.4469  1.11%   4.6  345s
 119327 13842 10097.4015   80   13 10117.9118 10007.7812  1.09%   4.6  350s
 121418 13639     cutoff   71      10117.9118 10010.5163  1.06%   4.6  355s
 123650 13459 10088.9288   76   17 10117.9118 10013.0271  1.04%   4.6  360s
 125853 13260     cutoff   78      10117.9118 10015.3596  1.01%   4.6  365s
 127927 13082 10092.1358   84   12 10117.9118 10017.6169  0.99%   4.6  370s
 130241 12864 10081.6774   80   15 10117.9118 10020.2338  0.97%   4.6  375s
 132536 12697     cutoff   74      10117.9118 10022.4453  0.94%   4.6  380s
 134785 12528     cutoff   80      10117.9118 10025.0578  0.92%   4.6  385s
 136971 12402 10073.1270   71   13 10117.9118 10027.6457  0.89%   4.6  390s
 139192 12193     cutoff   72      10117.9118 10029.8242  0.87%   4.6  395s
 141377 12032 10086.2638   77   16 10117.9118 10031.8734  0.85%   4.6  400s
 143531 11868 10102.4135   76   13 10117.9118 10033.8629  0.83%   4.6  405s
 145741 11656     cutoff   81      10117.9118 10036.2171  0.81%   4.6  410s
 147913 11434 10067.7484   75   15 10117.9118 10038.8088  0.78%   4.6  415s
 149968 11327     cutoff   79      10117.9118 10040.6996  0.76%   4.6  420s
 152229 11126     cutoff   81      10117.9118 10043.3612  0.74%   4.6  425s
 154491 10918 10074.2859   75   12 10117.9118 10045.6622  0.71%   4.6  430s
 156720 10643     cutoff   76      10117.9118 10047.8606  0.69%   4.6  435s
 158809 10288 10095.5006   76   18 10117.9118 10050.6052  0.67%   4.6  440s
 161037  9928 10075.2077   74   15 10117.9118 10053.4478  0.64%   4.6  445s
 163274  9481 10108.5331   76   14 10117.9118 10056.3407  0.61%   4.6  450s
 165520  8915 10106.3673   77   12 10117.9118 10059.7164  0.58%   4.6  455s
 167823  8306 10068.3457   75   12 10117.9118 10063.1074  0.54%   4.6  460s
 170137  7536 10091.9839   81   11 10117.9118 10067.1659  0.50%   4.6  465s
 172429  6706 10093.6697   77   14 10117.9118 10071.0545  0.46%   4.6  470s
 174631  5762 10075.2205   82    9 10117.9118 10075.1093  0.42%   4.6  475s
 176960  4557 10090.2344   75   12 10117.9118 10079.9012  0.38%   4.6  480s
 179086  3319     cutoff   76      10117.9118 10085.2032  0.32%   4.6  485s
*180663  2382             105    10117.911612 10090.4701  0.27%   4.6  488s
H180807  2304                    10117.909760 10091.0196  0.27%   4.6  488s
 181247  2062     cutoff   76      10117.9098 10093.0243  0.25%   4.6  490s
H181811  1724                    10117.909471 10095.6258  0.22%   4.6  491s
 183443   538     cutoff   80      10117.9095 10108.9939  0.09%   4.6  495s

Explored 184264 nodes (853801 simplex iterations) in 496.78 seconds (180.20 work units)
Thread count was 1 (of 56 available processors)

Solution count 10: 10117.9 10117.9 10118.1 ... 10126.9

Optimal solution found (tolerance 1.00e-06)
Best objective 1.011790947039e+04, best bound 1.011790175890e+04, gap 0.0001%

User-callback calls 671883, time in user-callback 0.46 sec
reading holmberg data file ../../../../../instances/uflp/holmberg/p32
primal_bound = 10117.909470390257, dual_bound = 10117.901758897478, gap = 7.621626583582504e-5, time = 496.79
OPTIMAL LOCATIONS:
y[1] = 1.0
y[2] = 1.0
y[3] = 1.0
y[4] = 1.0
y[5] = 1.0
y[6] = 1.0
y[7] = 1.0
y[8] = 1.0
y[9] = 1.0
y[10] = 1.0
y[11] = 1.0
y[12] = 1.0
y[13] = 1.0
y[14] = 1.0
y[15] = 1.0
y[16] = 1.0
y[17] = 1.0
y[18] = 1.0
y[19] = 1.0
y[20] = 1.0
y[21] = 1.0
y[22] = 1.0
y[23] = 1.0
y[24] = 1.0
y[25] = 1.0
y[26] = 1.0
y[27] = 1.0
y[28] = 1.0
y[29] = 1.0
y[30] = 1.0
OPTIMAL WAREHOUSING:
f[1] = 79.0
f[3] = 187.0
f[6] = 335.0
f[9] = 242.0
f[12] = 465.0
f[15] = 329.0
f[18] = 434.0
f[21] = 451.0
f[25] = 448.0
OPTIMAL WAREHOUSING COSTS:
nlobj[1] = 114.16509989340015
nlobj[2] = 0.0
nlobj[3] = 175.6464142740888
nlobj[4] = 0.0
nlobj[5] = 0.0
nlobj[6] = 235.09411755566322
nlobj[7] = 0.0
nlobj[8] = 0.0
nlobj[9] = 199.81472900145758
nlobj[10] = 0.0
nlobj[11] = 0.0
nlobj[12] = 276.9786484860732
nlobj[13] = 0.0
nlobj[14] = 0.0
nlobj[15] = 232.97920672019308
nlobj[16] = 0.0
nlobj[17] = 0.0
nlobj[18] = 267.5863876774684
nlobj[19] = 0.0
nlobj[20] = 0.0
nlobj[21] = 272.77707225922137
nlobj[22] = 0.0
nlobj[23] = 0.0
nlobj[24] = 0.0
nlobj[25] = 271.86779452269144
nlobj[26] = 0.0
nlobj[27] = 0.0
nlobj[28] = 0.0
nlobj[29] = 0.0
nlobj[30] = 0.0
OPTIMAL ASSIGNMENTS:
x[1, 41] = 1.0
x[1, 61] = 1.0
x[1, 68] = 1.0
x[1, 131] = 1.0
x[1, 141] = 1.0
x[3, 7] = 1.0
x[3, 21] = 1.0
x[3, 27] = 1.0
x[3, 91] = 1.0
x[3, 97] = 1.0
x[3, 105] = 1.0
x[3, 113] = 1.0
x[3, 149] = 1.0
x[6, 6] = 1.0
x[6, 19] = 1.0
x[6, 23] = 1.0
x[6, 25] = 1.0
x[6, 29] = 1.0
x[6, 31] = 1.0
x[6, 51] = 1.0
x[6, 54] = 1.0
x[6, 62] = 1.0
x[6, 90] = 1.0
x[6, 106] = 1.0
x[6, 121] = 1.0
x[6, 127] = 1.0
x[6, 134] = 1.0
x[6, 138] = 1.0
x[6, 148] = 1.0
x[6, 150] = 1.0
x[9, 12] = 1.0
x[9, 13] = 1.0
x[9, 26] = 1.0
x[9, 44] = 1.0
x[9, 50] = 1.0
x[9, 76] = 1.0
x[9, 101] = 1.0
x[9, 110] = 1.0
x[9, 122] = 1.0
x[9, 125] = 1.0
x[9, 135] = 1.0
x[9, 142] = 1.0
x[9, 145] = 1.0
x[12, 2] = 1.0
x[12, 20] = 1.0
x[12, 32] = 1.0
x[12, 34] = 1.0
x[12, 39] = 1.0
x[12, 49] = 1.0
x[12, 58] = 1.0
x[12, 59] = 1.0
x[12, 64] = 1.0
x[12, 65] = 1.0
x[12, 66] = 1.0
x[12, 73] = 1.0
x[12, 94] = 1.0
x[12, 99] = 1.0
x[12, 104] = 1.0
x[12, 108] = 1.0
x[12, 114] = 1.0
x[12, 115] = 1.0
x[12, 116] = 1.0
x[12, 123] = 1.0
x[12, 126] = 1.0
x[12, 129] = 1.0
x[12, 130] = 1.0
x[12, 132] = 1.0
x[12, 146] = 1.0
x[12, 147] = 1.0
x[15, 4] = 1.0
x[15, 9] = 1.0
x[15, 16] = 1.0
x[15, 17] = 1.0
x[15, 40] = 1.0
x[15, 42] = 1.0
x[15, 46] = 1.0
x[15, 52] = 1.0
x[15, 53] = 1.0
x[15, 60] = 1.0
x[15, 79] = 1.0
x[15, 109] = 1.0
x[15, 111] = 1.0
x[15, 112] = 1.0
x[15, 136] = 1.0
x[15, 144] = 1.0
x[18, 10] = 1.0
x[18, 15] = 1.0
x[18, 18] = 1.0
x[18, 22] = 1.0
x[18, 24] = 1.0
x[18, 47] = 1.0
x[18, 57] = 1.0
x[18, 74] = 1.0
x[18, 82] = 1.0
x[18, 84] = 1.0
x[18, 85] = 1.0
x[18, 86] = 1.0
x[18, 87] = 1.0
x[18, 88] = 1.0
x[18, 93] = 1.0
x[18, 95] = 1.0
x[18, 98] = 1.0
x[18, 102] = 1.0
x[18, 103] = 1.0
x[18, 107] = 1.0
x[18, 137] = 1.0
x[18, 140] = 1.0
x[21, 1] = 1.0
x[21, 3] = 1.0
x[21, 5] = 1.0
x[21, 14] = 1.0
x[21, 33] = 1.0
x[21, 35] = 1.0
x[21, 36] = 1.0
x[21, 48] = 1.0
x[21, 55] = 1.0
x[21, 56] = 1.0
x[21, 63] = 1.0
x[21, 71] = 1.0
x[21, 72] = 1.0
x[21, 78] = 1.0
x[21, 81] = 1.0
x[21, 83] = 1.0
x[21, 89] = 1.0
x[21, 100] = 1.0
x[21, 124] = 1.0
x[21, 139] = 1.0
x[21, 143] = 1.0
x[25, 8] = 1.0
x[25, 11] = 1.0
x[25, 28] = 1.0
x[25, 30] = 1.0
x[25, 37] = 1.0
x[25, 38] = 1.0
x[25, 43] = 1.0
x[25, 45] = 1.0
x[25, 67] = 1.0
x[25, 69] = 1.0
x[25, 70] = 1.0
x[25, 75] = 1.0
x[25, 77] = 1.0
x[25, 80] = 1.0
x[25, 92] = 1.0
x[25, 96] = 1.0
x[25, 117] = 1.0
x[25, 118] = 1.0
x[25, 119] = 1.0
x[25, 120] = 1.0
x[25, 128] = 1.0
x[25, 133] = 1.0
fixed costs = 21000.0
assignment costs = 8071.0
warehousing costs = 2046.9094703902572
total cost = 10117.909470390257
